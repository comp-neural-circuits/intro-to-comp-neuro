### Solution 2

In the scenario from the lecture, the pre-synaptic neurons influence the post-synaptic neuron with their spikes. In our scenario, the spike trains are independent. 
Therefore, the correlation between the input and the output spike trains always remains low. In the scenario from the lecture, the pre- and post-synaptic spike trains become more correlated when we enter the fluctuation driven regime. 

For STDP, the correlations can play a crucial row. In an extrem case, you can think of two neurons that are extremely highly correlated, one **always** spikes shortly after the other, even though both spike trains follow a Poisson distribution. The effect on the learning rule is therefore, that there is only potentiation, no matter how large the depression window would be. 

Coming back to the example, we can now look at the average correlation structure of the spike trains ([adapted from Song et al., 2000](https://doi.org/10.1038/78829)):
<div>
<img src="https://github.com/comp-neural-circuits/intro-to-comp-neuro/raw/dev/notebooks/Exc_6/static/stdp_song_miller_abbott_cited.png" width="750"/>
</div>

We see that already before the learning, there is a small peak for pre-post correlations. This makes sense since it is more likely that the post-synaptic neuron fires, if a pre-synaptic neuron has fired before. 

However, after the learning this peak increases drastically. Now the neuron is in the mean driven regime, which means it 'listens' much more to its presynaptic partners. Hence, the average correlation is stronger. 
To calculate the average weight change, one can calculate the convolution of the learning rule with the correlation structure, if the integral over this convolution is positive/negative, the average weight change is positive/negative as well.
