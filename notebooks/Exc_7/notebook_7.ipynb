{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607c9189",
   "metadata": {},
   "source": [
    "# Synaptic Plasticity in rate networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1216583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import ConnectionPatch as linepatch\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import ipywidgets as widgets\n",
    "import scipy\n",
    "from matplotlib.patches import Circle\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Settings for the figures\n",
    "plt.style.use(plt.style.available[20])\n",
    "plt.style.use(\"https://github.com/comp-neural-circuits/intro-to-comp-neuro/raw/dev/plots_style.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147082e5",
   "metadata": {},
   "source": [
    "# This notebook\n",
    "\n",
    "First you can remind yourself of the different possible plasticity rules in rate based networks.\n",
    "\n",
    "Then we look at these plasticity rules in action. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c3b8e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Overview of the different plasticity rules\n",
    "\n",
    "\\begin{align}\n",
    "ρ =& \\; \\text{presynaptic rate} \\\\\n",
    "v =& \\; \\text{postsynaptic rate}\n",
    "\\end{align}\n",
    "\n",
    "Simple Hebbian rule:\n",
    "\\begin{equation}\n",
    "    \\tau \\dot{w} = \\; v ρ\n",
    "\\end{equation}\n",
    "\n",
    "If we want to do some analysis on the weight evolution, the simple hebbian rule becomes the correlation based rule:\n",
    "\\begin{equation}\n",
    "    \\tau \\dot{w} = \\; C w \\\\ \n",
    "    C = ⟨ \\rho \\rho^{T} ⟩\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Threshold Hebbian rules:\n",
    "\\begin{align}\n",
    "    \\tau \\dot{w} =& \\; v (ρ - \\theta) \\\\\n",
    "    \\tau \\dot{w} =& \\; (v - \\theta) ρ \\\\\n",
    "    \\tau \\dot{w} =& \\; (v - \\theta) (ρ - \\theta)\n",
    "\\end{align}\n",
    "\n",
    "The threshold Hebbian rule becomes the covariance based rule (threshold in pre and post, where we select the threshold to be $ ⟨v⟩$ or $ ⟨ρ⟩$):\n",
    "\\begin{equation}\n",
    "    \\tau \\dot{w} = \\; Q w \\\\ \n",
    "    Q = ⟨ (\\nu - ⟨\\nu⟩) (\\rho - ⟨\\rho⟩)^{T}⟩\n",
    "\\end{equation}\n",
    "\n",
    "Hebbian rule with Subtractive normalization:\n",
    "\\begin{equation}\n",
    "    \\tau \\dot{w} = \\; Cw - \\frac{n^{T}Cw}{n^{T}n}n\n",
    "\\end{equation}\n",
    "\n",
    "Hebbian rule with Mulitplicative normalization:\n",
    "\\begin{equation}\n",
    "    \\tau \\dot{w} = \\; Cw - \\frac{n^{T}Cw}{n^{T}w}w\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "BCM rule:\n",
    "\\begin{align}\n",
    "    \\tau \\dot{w} =& \\; v(v-θ ) ρ \\\\\n",
    "    \\tau_{\\theta} \\dot{\\theta}  =& - θ + \\frac{\\bar{v}^{2}}{\\rho}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba9bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fbf632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [0 2 4]\n",
      " [0 3 6]]\n",
      "[[1 2 3]]\n",
      "[[0 0 0]\n",
      " [1 2 3]\n",
      " [2 4 6]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "y = np.array([0,1,2])\n",
    "\n",
    "print (np.dot(x[:,None],y[None,:]))\n",
    "r0 = x.reshape(1,-1)\n",
    "r1 = y.reshape(-1, 1)\n",
    "print (r0)\n",
    "print (np.dot(r1,r0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "055d68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_post(r_pre, r_post, w, dt, tau=20):\n",
    "       \n",
    "    dr_post = dt*(-r_post + np.sum(r_pre*w))/tau\n",
    "    \n",
    "    return r_post+dr_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4cf776b8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def hebbian(r0, r1, tau, dt=0.5, **params):\n",
    "\n",
    "    dw = (dt/tau) * np.dot(r1[:,None], r0[None,:])\n",
    "    return dw, 0\n",
    "\n",
    "def hebbian_threshold_pre(r0, r1, theta, tau, dt=0.5, **params):\n",
    "\n",
    "    dw = (dt/tau) * np.dot(r1[:,None], r0[None,:] - theta)\n",
    "  \n",
    "    return dw, 0\n",
    "\n",
    "def hebbian_threshold_post(r0, r1, theta, tau, dt=0.5, **params):\n",
    "\n",
    "    dw = (dt/tau) * np.dot(r1[:,None] - theta, r0[None,:])\n",
    "  \n",
    "    return dw, 0\n",
    "\n",
    "\n",
    "def hebbian_subtractive_normalization(r0, r1, tau, dt=0.5, **params):\n",
    "\n",
    "    dw1 = np.dot(r1[:,None], r0[None,:])   # simple Hebbian term\n",
    "    dw2 = np.sum(dw1)/np.size(dw1)        # subtractive normalization term\n",
    "    dw = (dt/tau) * (dw1 - dw2)\n",
    "    \n",
    "    return dw, 0\n",
    "\n",
    "def hebbian_multiplicative_norm(r0, r1, w, tau, dt=0.5, **params):\n",
    "\n",
    "    dw1 = np.dot(r1[:,None], r0[None,:])      # simple Hebbian term\n",
    "    dw2 = (np.sum(dw1)/np.sum(w)) * w       # multiplicative normalization term\n",
    "    dw = (dt/tau) * (dw1 - dw2)\n",
    "    return dw, 0\n",
    "\n",
    "# def bcm(r0, r1, theta, tau, tau_theta, r_target, dt=0.5, **params):\n",
    "    \n",
    "#     dw = (dt/tau) * np.dot(r1[:,None]*(r1[:,None]-theta), r0[None,:]) \n",
    "#     dtheta = (dt/tau_theta) * (-theta + r1[:,None]*r1[:,None]/r_target)\n",
    "\n",
    "#     return dw, dtheta[0,0]\n",
    "\n",
    "all_plasticity_functions = [\n",
    "    ('Hebbian',hebbian), \n",
    "    ('Hebbian Threshold Pre',hebbian_threshold_pre),\n",
    "    ('Hebbian Threshold Post',hebbian_threshold_post), \n",
    "    ('Hebbian Subtractive Normalization',hebbian_subtractive_normalization),\n",
    "    ('Hebbian Multiplicative Norm',hebbian_multiplicative_norm), \n",
    "#     ('BCM',bcm)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4d625d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple setup to understand the plasticity rules \n",
    "\n",
    "def investigate_plasticity_rules_simple(\n",
    "    plasticity_rule,\n",
    "    n_pre = 2,\n",
    "    upper_bound = 5, \n",
    "    theta_start = 0,\n",
    "    tau_theta = 40,\n",
    "    r_target = 12):\n",
    "    \n",
    "    tau_w = 1000\n",
    "    dt = 0.1\n",
    "    time_steps = 4000\n",
    "\n",
    "    \n",
    "    r_pre = np.array([4.,1.,2.,0.5])\n",
    "    r_pre = r_pre[:n_pre]\n",
    "    w = np.ones_like(r_pre)\n",
    "    r_post = np.array([0.])\n",
    "    \n",
    "\n",
    "    all_pre = r_pre[:]\n",
    "    all_post = r_post[:]\n",
    "    all_time = [0]\n",
    "    all_w = np.array([w])\n",
    "    \n",
    "    theta = theta_start\n",
    "    all_theta = [theta]\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for ii in range(time_steps):\n",
    "\n",
    "        r_post = evolve_post(r_pre, r_post, w, dt=dt)\n",
    "\n",
    "\n",
    "        dw, dtheta = plasticity_rule(r0=r_pre, r1 = r_post, theta=theta, w=w, tau=tau_w, tau_theta=tau_theta, r_target=r_target, dt=dt)\n",
    "    \n",
    "        theta += dtheta\n",
    "\n",
    "        w += dw.flatten()\n",
    "\n",
    "\n",
    "\n",
    "        w[w<0] = 0\n",
    "        w[w>upper_bound] = upper_bound\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if ii%15 == 0:\n",
    "            all_pre = np.vstack([all_pre, r_pre])\n",
    "            all_post = np.vstack([all_post, r_post])\n",
    "            all_time.append(ii*dt)\n",
    "            all_w = np.vstack([all_w,w])\n",
    "            all_theta.append(theta)\n",
    "            \n",
    "        \n",
    "    fig = plt.figure()\n",
    "    gs = GridSpec(3, 4)\n",
    "\n",
    "    # Create subplots using the GridSpec\n",
    "    ax1 = plt.subplot(gs[0, :-1]) \n",
    "    ax2 = plt.subplot(gs[1, :-1], sharex = ax1)  \n",
    "    ax3 = plt.subplot(gs[2, :-1])  \n",
    "    ax_img = plt.subplot(gs[:, 3]) \n",
    "\n",
    "    \n",
    "    ax1.plot(all_time,all_post, c='k')\n",
    "    if plasticity_rule == bcm or plasticity_rule == hebbian_threshold_post:\n",
    "        ax1.plot(all_time, all_theta, color = 'r', linestyle = '--', linewidth = 0.8, label = 'postsynaptic threshold')\n",
    "        ax1.legend()\n",
    "    ax1.set(\n",
    "        ylabel = 'Postsynaptic\\nactivity')\n",
    "    ax2.plot(all_time,all_w)\n",
    "    ax2.axhline(y=upper_bound, c='r', label = 'upper bound', linestyle ='--', linewidth=0.8)\n",
    "    ax2.legend()\n",
    "    ax2.set(\n",
    "        ylabel='Weight',\n",
    "        xlabel = 'Time in ms')\n",
    "    \n",
    "    all_ticks = []\n",
    "    all_tick_names = []\n",
    "    for ii, rr in enumerate(r_pre):\n",
    "        x_pos = 2*ii\n",
    "        ax3.bar([x_pos], rr)\n",
    "        all_ticks.append(x_pos)\n",
    "        all_tick_names.append(f'Presynaptic neuron {ii+1}')\n",
    "    ax3.set_xticks(all_ticks)\n",
    "    ax3.set_xticklabels(all_tick_names)\n",
    "    if plasticity_rule == hebbian_threshold_pre:\n",
    "        ax3.axhline(theta, color = 'r', linestyle = '--', linewidth = 0.8, label = 'presynaptic threshold')\n",
    "        ax3.legend()\n",
    "    ax3.set(\n",
    "        ylabel = 'Presynaptic\\nactivity',\n",
    "        ylim = [0,5],\n",
    "        xlim = [-1, 2*(len(r_pre)-1)+1])\n",
    "      \n",
    "\n",
    "    # Read the image data from the URL\n",
    "    url = f'https://github.com/comp-neural-circuits/intro-to-comp-neuro/raw/dev/notebooks/Exc_7/static/pre_to_post_{len(r_pre)}.png'\n",
    "    with urlopen(url) as f:\n",
    "        image = Image.open(f)\n",
    "\n",
    "    # Convert the image data to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Plot the image\n",
    "    ax_img.imshow(image_array)\n",
    "    \n",
    "    \n",
    "    ax_img.axis('off')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387295f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Task 1\n",
    "\n",
    "Here you can explore the different plasticity rules and how they act on a simple feedforward network with 1 to 4 presynaptic neurons.\n",
    "\n",
    "Take your time to explore the different scenarions. If you make an observation for a specific rule or have a question, please share those at the [Chatwall](https://tweedback.de/zkkh). There, you can also vote on other peoples findings or questions. \n",
    "(Before you post something, please check whether its already there first) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5d390330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a708bbdf7b4348e3b91a7dc728bad2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='plasticity_rule', options=(('Hebbian', <function hebbian at 0x0000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(investigate_plasticity_rules_simple, \n",
    "                    plasticity_rule = all_plasticity_functions,\n",
    "                   upper_bound = (1,10,1),\n",
    "                   theta_start = (0,10,1),\n",
    "                   tau_theta = (0.5,4,0.5),\n",
    "                   r_target = (0,40,2),\n",
    "                   n_pre = (1,4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e8421",
   "metadata": {},
   "source": [
    "Below, we add some helper functions that help styling the complex case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7adf9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# manual circular colormap\n",
    "circular_colors = [\n",
    " [0.658308, 0.469939, 0.049413],\n",
    " [0.744038, 0.407172, 0.156543],\n",
    " [0.810445, 0.335882, 0.263072],\n",
    " [0.857457, 0.252094, 0.398416],\n",
    " [0.872591, 0.166185, 0.578329],\n",
    " [0.836934, 0.161108, 0.76804],\n",
    " [0.753424, 0.255361, 0.899179],\n",
    " [0.636852, 0.359561, 0.954059],\n",
    " [0.49199, 0.449706, 0.941785],\n",
    " [0.321912, 0.520685, 0.862792],\n",
    " [0.171942, 0.563517, 0.737535],\n",
    " [0.096568, 0.584234, 0.611819],\n",
    " [0.045551, 0.598018, 0.485098],\n",
    " [0.14238, 0.603831, 0.323267],\n",
    " [0.368179, 0.578986, 0.125801],\n",
    " [0.543825, 0.52618, 0.052752]]\n",
    "\n",
    "\n",
    "def create_line_for_angle(n_shift, ax):\n",
    "        \n",
    "        x = np.linspace(0,180,17)\n",
    "        angle = x[n_shift]/360.*2*np.pi\n",
    "        gain = np.tan(angle)\n",
    "        line_length = 1\n",
    "        center = np.array([calc_x_shift(n_shift),0.05])\n",
    "\n",
    "        a = np.array([np.cos(angle),np.sin(angle)])/60.\n",
    "        b = np.array([-np.cos(angle),-np.sin(angle)])/60.\n",
    "\n",
    "        con = linepatch(\n",
    "            a+center, \n",
    "            b+center, \n",
    "            'figure fraction',color=circular_colors[n_shift],linewidth=3)\n",
    "        ax.add_artist(con)\n",
    "        \n",
    "        return con\n",
    "def calc_x_shift(n_shift):\n",
    "    return 0.14+n_shift*0.0512\n",
    "\n",
    "def create_angle_illustration(ax, n_pre):\n",
    "    for ii in range(n_pre):\n",
    "        create_line_for_angle(n_shift=ii,ax=ax)\n",
    "        \n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    \n",
    "def gaussian(x, mu, sig):    \n",
    "    x = np.copy(x)\n",
    "    stacked = np.vstack([np.abs(x-mu),np.abs((x-len(x))-mu),np.abs((x+len(x))-mu)])\n",
    "    arg = np.argmin(stacked,axis=0)\n",
    "    \n",
    "    x[arg == 1] = x[arg == 1]-len(x)\n",
    "    x[arg == 2] = x[arg == 2]+len(x)\n",
    "   \n",
    "    gaussian = np.exp((-((x - mu)/sig)**2.)/2)\n",
    "    norm = np.sum(gaussian)\n",
    "    \n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420c532",
   "metadata": {},
   "source": [
    "# Complex input patterns\n",
    "\n",
    "We now want to look at a more complex case, where \n",
    "1) we have 16 inputs. We can think of them as neurons that are tuned to specific orientations (i.e. if one orientation is presented, the corresponding neuron will respond the most) \n",
    "\n",
    "2) The inputs vary now over time, such that the activity of the presynaptic neuron also changes over time.\n",
    "\n",
    "I would be great if the postsynaptic neuron could learn the weights, so that it listens only to a couple of neurons and therefore itself would be tuned to a specific orientation (or mixture of orientations) presented. Can you achieve this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "96dac19e",
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    plasticity_rule,seed=10,theta_start = 0.4, weight_bias=False, gaussian_inputs=True, time_step=-1):\n",
    "\n",
    "    plasticity_rule = plasticity_rule\n",
    "\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    n_pre = 16\n",
    "    upper_bound = 5\n",
    "\n",
    "    tau_theta = 1\n",
    "    r_target = 8\n",
    "\n",
    "    tau_w = 700\n",
    "    dt = 0.1\n",
    "    time_steps = 6000\n",
    "\n",
    "    r_pre = np.ones(n_pre)\n",
    "    r_pre = r_pre[:n_pre]\n",
    "    r_post = np.array([0.])\n",
    "\n",
    "    X = np.linspace(0,n_pre-1,n_pre)\n",
    "    mu = np.random.choice(n_pre)\n",
    "    sig = 2\n",
    "    if not gaussian_inputs:\n",
    "        sig = 0.6\n",
    "    w = np.ones_like(r_pre)*2\n",
    "    if weight_bias:\n",
    "        w *= gaussian(x=X, mu=mu,sig=5) \n",
    "\n",
    "    all_pre = r_pre[:]\n",
    "    all_post = r_post[:]\n",
    "    all_time = [0]\n",
    "    all_w = np.array([w])\n",
    "    all_angles = [mu]\n",
    "\n",
    "    theta = theta_start\n",
    "    all_theta = [theta]\n",
    "\n",
    "\n",
    "\n",
    "    starting_w = np.copy(w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for ii in range(time_steps):\n",
    "\n",
    "        if np.random.rand() > 0.995:\n",
    "            mu = np.random.choice(n_pre)\n",
    "\n",
    "\n",
    "        input_pattern = gaussian(x=X, mu=mu,sig=sig) + 0.0\n",
    "\n",
    "        r_pre = input_pattern\n",
    "    \n",
    "        r_post = evolve_post(r_pre, r_post, w, dt=dt)\n",
    "\n",
    "        dw, dtheta = plasticity_rule(r0=r_pre, r1 = r_post, theta=theta, w=w, tau=tau_w, tau_theta=tau_theta, r_target=r_target, dt=dt)\n",
    "\n",
    "        theta += dtheta\n",
    "\n",
    "        w += dw.flatten()\n",
    "\n",
    "\n",
    "\n",
    "        w[w<0] = 0\n",
    "        w[w>upper_bound] = upper_bound\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if ii%15 == 0:\n",
    "            all_pre = np.vstack([all_pre, r_pre])\n",
    "            all_post = np.vstack([all_post, r_post])\n",
    "            all_time.append(ii*dt)\n",
    "            all_w = np.vstack([all_w,w])\n",
    "            all_angles.append(mu)\n",
    "            all_theta.append(theta)\n",
    "\n",
    "\n",
    "\n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(3,1, gridspec_kw={'height_ratios': [1, 3,3]})\n",
    "\n",
    "\n",
    "    ax1.plot(all_time[:time_step],all_post[:time_step])\n",
    "    if plasticity_rule == bcm or plasticity_rule == hebbian_threshold_post:\n",
    "        ax1.plot(all_time[:time_step], all_theta[:time_step], color = 'r', linestyle = '--', linewidth = 0.8, label = 'postsynaptic threshold')\n",
    "        ax1.legend()\n",
    "    ax1.set(\n",
    "        xlim = [0,all_time[-1]],\n",
    "        ylabel = 'Output rate')\n",
    "    for cc, ww in zip(circular_colors,all_w[:time_step,:].T):\n",
    "        ax2.plot(all_time[:time_step],ww, c=cc)\n",
    "\n",
    "    ax2.set(\n",
    "        xlim = [0,all_time[-1]],\n",
    "        xlabel = 'Time in ms',\n",
    "        ylabel = 'Input weights')\n",
    "    for ii, (pre,cc) in enumerate(zip(all_pre[time_step],circular_colors)):\n",
    "        ax3.bar([ii],pre, edgecolor = cc, linewidth = 2, facecolor='#f0f0f0', width=0.5)\n",
    "    ax3.set(\n",
    "        ylabel = 'Input Rate',\n",
    "        ylim = [0,np.max(all_pre)*1.1])\n",
    "\n",
    "    ax3.axvline(all_angles[time_step], linestyle = '--', c='k', label = 'stimulus')\n",
    "    if plasticity_rule == hebbian_threshold_pre:\n",
    "        ax3.axhline(all_theta[-1], color = 'r', linestyle = '--', linewidth = 0.8, label = 'presynaptic threshold')\n",
    "    ax3.legend()\n",
    "    create_angle_illustration(ax3, n_pre)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1,figsize =(6,3))\n",
    "    ax.set(\n",
    "        title = 'Weight and input distributions',\n",
    "        xlabel = 'Input Neuron',\n",
    "        ylabel = 'weight/scaled input'\n",
    "    )\n",
    "    ax.bar([ii-0.3 for ii in range(len(w))],starting_w, edgecolor = 'k', linewidth = 0.15, facecolor='#66c2a5', width=0.2, label = 'starting weights')\n",
    "    ax.bar([ii+0.3 for ii in range(len(w))],w, edgecolor = 'k', linewidth = 0.15, facecolor='#fc8d62', width=0.2, label = 'ending weights')\n",
    "    mean_input = np.mean(all_pre,axis=0)\n",
    "    mean_input /= np.max(mean_input)\n",
    "    mean_input *= np.max(w)\n",
    "\n",
    "    ax.bar([ii for ii in range(len(w))],mean_input, edgecolor = 'k', linewidth = 0.15, facecolor='#8da0cb', width=0.2, label = 'mean input')\n",
    "    ax.legend()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4bcadbd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ed5007afd743488b6184a35e28a238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='plasticity_rule', options=(('Hebbian', <function hebbian at 0x0000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interactive(\n",
    "    run_simulation, \n",
    "    plasticity_rule = all_plasticity_functions,\n",
    "    theta_start = (0.1,20,0.1),\n",
    "    time_step = (-1,200,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "95f95c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "intro-to-comp-neuro",
   "language": "python",
   "name": "intro-to-comp-neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
